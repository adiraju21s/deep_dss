{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The pgf.debug rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "In /Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from deep_dss.utils import *\n",
    "from deep_dss.models import *\n",
    "\n",
    "import numpy as np\n",
    "from deepsphere.data import LabeledDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting memscript.py\n"
     ]
    }
   ],
   "source": [
    "%%file memscript.py\n",
    "import os\n",
    "\n",
    "from deep_dss.utils import *\n",
    "from deep_dss.models import *\n",
    "\n",
    "import numpy as np\n",
    "from deepsphere.data import LabeledDataset\n",
    "\n",
    "def train():\n",
    "    def total_channels(c):\n",
    "        if c[0] == \"c\":\n",
    "            return 1 + lensing_channels(c[1:])\n",
    "        return lensing_channels(c)\n",
    "\n",
    "\n",
    "    config = \"c\"\n",
    "    channels = total_channels(config)\n",
    "    order = 2\n",
    "    nmaps = 10\n",
    "    k = 64\n",
    "    epochs1 = 20\n",
    "    epochs2 = 10\n",
    "    lr1 = 1e-4\n",
    "    lr2 = 2e-5\n",
    "\n",
    "    val_dict = split_count_and_lensing_maps_by_dataset(\"TEST\", config=config, order=order,\n",
    "                                                       scramble=True)\n",
    "    val_dict[\"x\"] = val_dict[\"x\"][:64]\n",
    "    val_dict[\"y\"] = val_dict[\"y\"][:64]\n",
    "\n",
    "    val = LabeledDataset(val_dict[\"x\"], val_dict[\"y\"])\n",
    "\n",
    "    train_dict = split_count_and_lensing_maps_by_dataset(\"Q1\", config=config, noiseless_m=True,\n",
    "                                                         noiseless_kg=True, order=order,\n",
    "                                                         scramble=True)\n",
    "    train_dict[\"x\"] = train_dict[\"x\"][:nmaps * 12 * order * order]\n",
    "    train_dict[\"y\"] = train_dict[\"y\"][:nmaps * 12 * order * order]\n",
    "\n",
    "    train = LabeledDataset(train_dict[\"x\"], train_dict[\"y\"])\n",
    "\n",
    "    model = model_by_architecture(\"data1\", num_epochs=epochs1, learning_rate=lr1, input_channels=channels, nmaps=nmaps,\n",
    "                                  order=order, exp_name=\"counts-base\", nfilters=k)\n",
    "\n",
    "#     accuracy_validation, loss_validation, loss_training, t_step = model.fit(train, val)\n",
    "\n",
    "#     np.savez_compressed(\"vdata1-counts-base-metrics-1.npz\", lval=loss_validation, ltrain=loss_training, t=t_step)\n",
    "\n",
    "#     train_dict = split_count_and_lensing_maps_by_dataset(\"Q1\", config=config, order=order,\n",
    "#                                                          scramble=True)\n",
    "#     train_dict[\"x\"] = train_dict[\"x\"][:nmaps * 12 * order * order]\n",
    "#     train_dict[\"y\"] = train_dict[\"y\"][:nmaps * 12 * order * order]\n",
    "\n",
    "#     train = LabeledDataset(train_dict[\"x\"], train_dict[\"y\"])\n",
    "\n",
    "#     model = model_by_architecture(\"data1\", num_epochs=epochs2, learning_rate=lr2, input_channels=channels, nmaps=nmaps,\n",
    "#                                   order=order, exp_name=\"counts-base\", nfilters=k)\n",
    "\n",
    "#     accuracy_validation, loss_validation, loss_training, t_step = model.fit(train, val, session=model._get_session())\n",
    "\n",
    "#     np.savez_compressed(\"vdata1-counts-base-metrics-2.npz\", lval=loss_validation, ltrain=loss_training, t=t_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memscript import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.6/site-packages/healpy/fitsfunc.py:352: UserWarning: If you are not specifying the input dtype and using the default np.float64 dtype of read_map(), please consider that it will change in a future version to None as to keep the same dtype of the input file: please explicitly set the dtype if it is important to you.\n",
      "  \"If you are not specifying the input dtype and using the default \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "NSIDE = 1024\n",
      "ORDERING = NESTED in fits file\n",
      "INDXSCHM = IMPLICIT\n",
      "#sides: [1024, 512, 256, 128, 64, 32, 16, 8, 4]\n",
      "#pixels: [262144, 65536, 16384, 4096, 1024, 256, 64, 16, 4]\n",
      "#samples per batch: 64\n",
      "=> #pixels per batch (input): 16,777,216\n",
      "=> #pixels for training (input): 2,516,582,400\n",
      "NN architecture\n",
      "  input: M_0 = 262144\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 262144 * 64 / 4 = 4194304\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 64 * 5 = 320\n",
      "    biases: F_1 = 64\n",
      "    batch normalization\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 65536 * 64 / 4 = 1048576\n",
      "    weights: F_1 * F_2 * K_2 = 64 * 64 * 5 = 20480\n",
      "    biases: F_2 = 64\n",
      "    batch normalization\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 16384 * 64 / 4 = 262144\n",
      "    weights: F_2 * F_3 * K_3 = 64 * 64 * 5 = 20480\n",
      "    biases: F_3 = 64\n",
      "    batch normalization\n",
      "  layer 4: cgconv4\n",
      "    representation: M_3 * F_4 / p_4 = 4096 * 64 / 4 = 65536\n",
      "    weights: F_3 * F_4 * K_4 = 64 * 64 * 5 = 20480\n",
      "    biases: F_4 = 64\n",
      "    batch normalization\n",
      "  layer 5: cgconv5\n",
      "    representation: M_4 * F_5 / p_5 = 1024 * 64 / 4 = 16384\n",
      "    weights: F_4 * F_5 * K_5 = 64 * 64 * 5 = 20480\n",
      "    biases: F_5 = 64\n",
      "    batch normalization\n",
      "  layer 6: cgconv6\n",
      "    representation: M_5 * F_6 / p_6 = 256 * 64 / 4 = 4096\n",
      "    weights: F_5 * F_6 * K_6 = 64 * 64 * 5 = 20480\n",
      "    biases: F_6 = 64\n",
      "    batch normalization\n",
      "  layer 7: cgconv7\n",
      "    representation: M_6 * F_7 / p_7 = 64 * 64 / 4 = 1024\n",
      "    weights: F_6 * F_7 * K_7 = 64 * 64 * 5 = 20480\n",
      "    biases: F_7 = 64\n",
      "    batch normalization\n",
      "  layer 8: cgconv8\n",
      "    representation: M_7 * F_8 / p_8 = 16 * 64 / 4 = 256\n",
      "    weights: F_7 * F_8 * K_8 = 64 * 64 * 5 = 20480\n",
      "    biases: F_8 = 64\n",
      "    batch normalization\n",
      "  layer 9: fc1\n",
      "    representation: M_9 = 1\n",
      "    weights: M_8 * M_9 = 256 * 1 = 256\n",
      "peak memory: 5602.72 MiB, increment: 5329.55 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
