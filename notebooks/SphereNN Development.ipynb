{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Run Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from deep_dss.helpers import *\n",
    "\n",
    "# Run on GPU.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults\n",
    "plt.rcParams.update({\n",
    "'lines.color':'black',\n",
    "'font.family':'serif',\n",
    "'font.weight':'normal',\n",
    "'text.color':'black',\n",
    "'text.usetex': True,\n",
    "'axes.edgecolor':'black',\n",
    "'axes.linewidth':1.0,\n",
    "'axes.titlesize':'x-large',\n",
    "'axes.labelsize':'x-large',\n",
    "'axes.labelcolor':'black',\n",
    "'xtick.labelsize':'x-large',\n",
    "'xtick.minor.width':1.0,\n",
    "'xtick.major.width':1.0,\n",
    "'ytick.major.size':7,\n",
    "'ytick.minor.size':4,\n",
    "'ytick.major.pad':8,\n",
    "'ytick.minor.pad':8,\n",
    "'ytick.labelsize':'x-large',\n",
    "'ytick.minor.width':1.0,\n",
    "'ytick.major.width':1.0,\n",
    "'legend.numpoints':1,\n",
    "'legend.fontsize':'x-large',\n",
    "'legend.shadow':False,\n",
    "'legend.frameon':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../checkpoints/spherenn/spherenn-v3-simple-noiseless-fixed-gamma: File exists\n",
      "mkdir: ../log/spherenn-v3-simple-noiseless-fixed-gamma: File exists\n",
      "mkdir: ../figures/spherenn-v3-simple-noiseless-fixed-gamma: File exists\n"
     ]
    }
   ],
   "source": [
    "config = \"g\"\n",
    "channels = 2\n",
    "noiseless_m = True\n",
    "noiseless_kg = True\n",
    "rand_bias = False\n",
    "mixed_bias = False\n",
    "gaussian = False\n",
    "\n",
    "order = 2\n",
    "nside = 1024\n",
    "\n",
    "val_set = \"TEST\"\n",
    "\n",
    "exp_name = \"spherenn-v3-simple-noiseless-fixed-gamma\"\n",
    "num_id = 1\n",
    "checkpoint_path = \"../checkpoints/spherenn/{0}/{0}-{1}\".format(exp_name, num_id)\n",
    "checkpoint_dir = \"../checkpoints/spherenn/{0}\".format(exp_name)\n",
    "!mkdir $checkpoint_dir\n",
    "log_dir = \"../log/{0}\".format(exp_name)\n",
    "!mkdir $log_dir\n",
    "fig_dir = \"../figures/{0}\".format(exp_name)\n",
    "!mkdir $fig_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_cosmologies(dataset):\n",
    "    if dataset == \"TRAINLITE\":\n",
    "        return 16\n",
    "    if dataset == \"TESTLITE\":\n",
    "        return 4\n",
    "    if dataset == \"TEST\":\n",
    "        return 21\n",
    "    return 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reshaped_data(dataset):\n",
    "    print(\"Generating data for {0}!\".format(dataset))\n",
    "    num_cosmos = num_cosmologies(dataset)\n",
    "    data = split_count_and_lensing_maps_by_dataset(dataset, config=config, noiseless_m=noiseless_m,\n",
    "                                                  noiseless_kg=noiseless_kg, rand_bias=rand_bias, \n",
    "                                                  mixed_bias=mixed_bias, gaussian=gaussian)\n",
    "    data[\"x\"] = np.reshape(data[\"x\"], (12*(order**2)*num_cosmos, (nside//order)**2, channels))\n",
    "    data[\"y\"] = np.reshape(data[\"y\"], (12*(order**2)*num_cosmos, 1, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    return keras.Sequential([\n",
    "        keras.Input(shape=(262144, channels)),\n",
    "        keras.layers.Conv1D(64, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(128, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(256, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(256, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(256, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(256, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(256, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(256, 4, strides=4, activation='relu'),\n",
    "        keras.layers.Conv1D(1, 4, strides=4, activation='relu'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_single_dataset(dataset, n_epochs=12, load_model=False, chkpt_path=None, val_data=None):    \n",
    "    train_data = generate_reshaped_data(dataset)\n",
    "    if val_data is None:\n",
    "        val_data = generate_reshaped_data(val_set)\n",
    "    \n",
    "    model = build_model()\n",
    "    if load_model:\n",
    "        model.load_weights(chkpt_path)\n",
    "    model.compile(optimizer=\"adam\", loss=tf.keras.losses.MAE, metrics=[])\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir+\"/{0}-{1}\".format(num_id, dataset),\n",
    "                                                          histogram_freq=1)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path+\"-{0}\".format(dataset),\n",
    "                                                     monitor=\"val_loss\", save_weights_only=True, save_best_only=True, \n",
    "                                                     verbose=1, mode=\"min\")\n",
    "    \n",
    "    model.fit(x=train_data[\"x\"], y=train_data[\"y\"], batch_size=32, epochs=n_epochs, \n",
    "              validation_data=(val_data[\"x\"], val_data[\"y\"]),\n",
    "              callbacks=[tensorboard_callback, cp_callback])\n",
    "    return checkpoint_path+\"-{0}\".format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    val_data = generate_reshaped_data(val_set)\n",
    "    print(\"Training on Q1 data:\")\n",
    "    path = train_model_single_dataset(\"Q1\", val_data=val_data)\n",
    "    print(\"Training on Q2 data:\")\n",
    "    path = train_model_single_dataset(\"Q2\", load_model=True, chkpt_path=path, val_data=val_data)\n",
    "    print(\"Training on Q3 data:\")\n",
    "    path = train_model_single_dataset(\"Q3\", load_model=True, chkpt_path=path, val_data=val_data)\n",
    "    print(\"Training on Q4 data:\")\n",
    "    train_model_single_dataset(\"Q4\", load_model=True, chkpt_path=path, val_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_predictions_and_truths():\n",
    "    model = build_model()\n",
    "    model.load_weights(checkpoint_path+\"-Q4\")\n",
    "    \n",
    "    print(\"Processing Q1 data\")\n",
    "    data = generate_reshaped_data(\"Q1\")\n",
    "    preds_q1 = model.predict(data[\"x\"])\n",
    "    truths_q1 = data[\"y\"]\n",
    "    q1 = {\"p\": preds_q1, \"t\": truths_q1}\n",
    "    \n",
    "    print(\"Processing Q2 data\")\n",
    "    data = generate_reshaped_data(\"Q2\")\n",
    "    preds_q2 = model.predict(data[\"x\"])\n",
    "    truths_q2 = data[\"y\"]\n",
    "    q2 = {\"p\": preds_q2, \"t\": truths_q2}\n",
    "\n",
    "    print(\"Processing Q3 data\")    \n",
    "    data = generate_reshaped_data(\"Q3\")\n",
    "    preds_q3 = model.predict(data[\"x\"])\n",
    "    truths_q3 = data[\"y\"]\n",
    "    q3 = {\"p\": preds_q3, \"t\": truths_q3}\n",
    "    \n",
    "    print(\"Processing Q4 data\")\n",
    "    data = generate_reshaped_data(\"Q4\")\n",
    "    preds_q4 = model.predict(data[\"x\"])\n",
    "    truths_q4 = data[\"y\"]\n",
    "    q4 = {\"p\": preds_q4, \"t\": truths_q4}\n",
    "    \n",
    "    print(\"Processing TEST data\")\n",
    "    data = generate_reshaped_data(\"TEST\")\n",
    "    preds_test = model.predict(data[\"x\"])\n",
    "    truths_test = data[\"y\"]\n",
    "    test = {\"p\": preds_test, \"t\": truths_test}\n",
    "    \n",
    "    return {\"Q1\": q1, \"Q2\": q2, \"Q3\": q3, \"Q4\": q4, \"TEST\": test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_predictions(full_results):\n",
    "    pickle.dump(full_results, open(\"{0}/{1}-{2}-full-preds.pkl\".format(fig_dir, exp_name, num_id), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions():\n",
    "    return pickle.load(open(\"{0}/{1}-{2}-full-preds.pkl\".format(fig_dir, exp_name, num_id), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_losses(full_results):\n",
    "    with open(\"{0}/{1}-{2}-losses.txt\".format(fig_dir, exp_name, num_id), \"w\") as logfile:\n",
    "        print(\"Average Q1 Loss:\", np.average(np.abs(full_results[\"Q1\"][\"p\"] - full_results[\"Q1\"][\"t\"])), file=logfile)\n",
    "        print(\"Average Q2 Loss:\", np.average(np.abs(full_results[\"Q2\"][\"p\"] - full_results[\"Q2\"][\"t\"])), file=logfile)\n",
    "        print(\"Average Q3 Loss:\", np.average(np.abs(full_results[\"Q3\"][\"p\"] - full_results[\"Q3\"][\"t\"])), file=logfile)\n",
    "        print(\"Average Q4 Loss:\", np.average(np.abs(full_results[\"Q4\"][\"p\"] - full_results[\"Q4\"][\"t\"])), file=logfile)\n",
    "        print(\"Average TEST Loss:\", np.average(np.abs(full_results[\"TEST\"][\"p\"] - full_results[\"TEST\"][\"t\"])),\n",
    "             file=logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds_vs_truths(full_results, title):\n",
    "    plt.rcParams.update({\n",
    "        'lines.color':'black',\n",
    "        'font.family':'serif',\n",
    "        'font.weight':'normal',\n",
    "        'text.color':'black',\n",
    "        'text.usetex': True,\n",
    "        'axes.edgecolor':'black',\n",
    "        'axes.linewidth':1.0,\n",
    "        'axes.titlesize':'x-large',\n",
    "        'axes.labelsize':'x-large',\n",
    "        'axes.labelcolor':'black',\n",
    "        'xtick.labelsize':'x-large',\n",
    "        'xtick.minor.width':1.0,\n",
    "        'xtick.major.width':1.0,\n",
    "        'ytick.major.size':7,\n",
    "        'ytick.minor.size':4,\n",
    "        'ytick.major.pad':8,\n",
    "        'ytick.minor.pad':8,\n",
    "        'ytick.labelsize':'x-large',\n",
    "        'ytick.minor.width':1.0,\n",
    "        'ytick.major.width':1.0,\n",
    "        'legend.numpoints':1,\n",
    "        'legend.fontsize':'x-large',\n",
    "        'legend.shadow':False,\n",
    "        'legend.frameon':False})\n",
    "    \n",
    "    plt.scatter(full_results[\"Q1\"][\"t\"][:,0,0], full_results[\"Q1\"][\"p\"][:,0,0], label=\"q1\")    \n",
    "    plt.scatter(full_results[\"Q2\"][\"t\"][:,0,0], full_results[\"Q2\"][\"p\"][:,0,0], label=\"q2\")    \n",
    "    plt.scatter(full_results[\"Q3\"][\"t\"][:,0,0], full_results[\"Q3\"][\"p\"][:,0,0], label=\"q3\")    \n",
    "    plt.scatter(full_results[\"Q4\"][\"t\"][:,0,0], full_results[\"Q4\"][\"p\"][:,0,0], label=\"q4\")    \n",
    "    plt.scatter(full_results[\"TEST\"][\"t\"][:,0,0], full_results[\"TEST\"][\"p\"][:,0,0], label=\"test\")    \n",
    "    plt.plot([0.5, 1.2], [0.5, 1.2], \"k-\", linewidth=4, label=\"ground truth\")\n",
    "    \n",
    "    plt.xlabel(r\"True clustering of matter ($\\sigma_8$)\")\n",
    "    plt.ylabel(r\"Predicted clustering of matter ($\\widehat{\\sigma_8}$)\")\n",
    "    plt.title(title)\n",
    "    \n",
    "#     linreg = np.polyfit(full_results[\"TEST\"][\"t\"][:,0,0], p(full_results[\"TEST\"][\"t\"][:,0,0]), 1)\n",
    "#     p = np.poly1d(linreg)\n",
    "#     plt.plot(val[\"y\"][:,0,0], val[\"y\"][:,0,0], \"k-\", linewidth=4, label='linear fit')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(\"{0}/{1}-{2}-full-preds-vs-truths.png\".format(fig_dir, exp_name, num_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(full_results, title):\n",
    "    plt.rcParams.update({\n",
    "        'lines.color':'black',\n",
    "        'font.family':'serif',\n",
    "        'font.weight':'normal',\n",
    "        'text.color':'black',\n",
    "        'text.usetex': True,\n",
    "        'axes.edgecolor':'black',\n",
    "        'axes.linewidth':1.0,\n",
    "        'axes.titlesize':'x-large',\n",
    "        'axes.labelsize':'x-large',\n",
    "        'axes.labelcolor':'black',\n",
    "        'xtick.labelsize':'x-large',\n",
    "        'xtick.minor.width':1.0,\n",
    "        'xtick.major.width':1.0,\n",
    "        'ytick.major.size':7,\n",
    "        'ytick.minor.size':4,\n",
    "        'ytick.major.pad':8,\n",
    "        'ytick.minor.pad':8,\n",
    "        'ytick.labelsize':'x-large',\n",
    "        'ytick.minor.width':1.0,\n",
    "        'ytick.major.width':1.0,\n",
    "        'legend.numpoints':1,\n",
    "        'legend.fontsize':'small',\n",
    "        'legend.shadow':False,\n",
    "        'legend.frameon':False})\n",
    "    \n",
    "    plt.scatter(full_results[\"Q1\"][\"t\"][:,0,0], full_results[\"Q1\"][\"p\"][:,0,0]-full_results[\"Q1\"][\"t\"][:,0,0],\n",
    "                label=\"q1\")    \n",
    "    plt.scatter(full_results[\"Q2\"][\"t\"][:,0,0], full_results[\"Q2\"][\"p\"][:,0,0]-full_results[\"Q2\"][\"t\"][:,0,0],\n",
    "                label=\"q2\")    \n",
    "    plt.scatter(full_results[\"Q3\"][\"t\"][:,0,0], full_results[\"Q3\"][\"p\"][:,0,0]-full_results[\"Q3\"][\"t\"][:,0,0],\n",
    "                label=\"q3\")    \n",
    "    plt.scatter(full_results[\"Q4\"][\"t\"][:,0,0], full_results[\"Q4\"][\"p\"][:,0,0]-full_results[\"Q4\"][\"t\"][:,0,0],\n",
    "                label=\"q4\")    \n",
    "    plt.scatter(full_results[\"TEST\"][\"t\"][:,0,0], full_results[\"TEST\"][\"p\"][:,0,0]-full_results[\"TEST\"][\"t\"][:,0,0],\n",
    "                label=\"test\")    \n",
    "    plt.plot([0.5, 1.2], [0, 0], \"k-\", linewidth=4, label=\"ground truth\")\n",
    "    \n",
    "#     linreg = np.polyfit(full_results[\"TEST\"][\"t\"][:,0,0], p(full_results[\"TEST\"][\"t\"][:,0,0]), 1)\n",
    "#     p = np.poly1d(linreg)\n",
    "#     plt.plot(val[\"y\"][:,0,0], val[\"y\"][:,0,0], \"k-\", linewidth=4, label='linear fit')\n",
    "\n",
    "    plt.xlabel(r\"True clustering of matter ($\\sigma_8$)\")\n",
    "    plt.ylabel(r\"Error in model prediction ($\\widehat{\\sigma_8} - \\sigma_8$)\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.ylim(-0.1, 0.1)\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(\"{0}/{1}-{2}-full-residuals.png\".format(fig_dir, exp_name, num_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 65536, 64)         576       \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16384, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 4096, 256)         131328    \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1024, 256)         262400    \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 256, 256)          262400    \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 64, 256)           262400    \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 16, 256)           262400    \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 4, 256)            262400    \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 1, 1)              1025      \n",
      "=================================================================\n",
      "Total params: 1,477,825\n",
      "Trainable params: 1,477,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dummy_model = build_model()\n",
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for TEST!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:368: UserWarning: If you are not specifying the input dtype and using the default np.float64 dtype of read_map(), please consider that it will change in a future version to None as to keep the same dtype of the input file: please explicitly set the dtype if it is important to you.\n",
      "  warnings.warn(\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:391: UserWarning: NSIDE = 1024\n",
      "  warnings.warn(\"NSIDE = {0:d}\".format(nside))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:400: UserWarning: ORDERING = NESTED in fits file\n",
      "  warnings.warn(\"ORDERING = {0:s} in fits file\".format(ordering))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:428: UserWarning: INDXSCHM = IMPLICIT\n",
      "  warnings.warn(\"INDXSCHM = {0:s}\".format(schm))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Q1 data:\n",
      "Generating data for Q1!\n",
      "Epoch 1/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3586\n",
      "Epoch 00001: val_loss improved from inf to 0.19842, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q1\n",
      "68/68 [==============================] - 154s 2s/step - loss: 0.3586 - val_loss: 0.1984\n",
      "Epoch 2/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1670\n",
      "Epoch 00002: val_loss improved from 0.19842 to 0.13096, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q1\n",
      "68/68 [==============================] - 141s 2s/step - loss: 0.1670 - val_loss: 0.1310\n",
      "Epoch 3/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1479\n",
      "Epoch 00003: val_loss did not improve from 0.13096\n",
      "68/68 [==============================] - 144s 2s/step - loss: 0.1479 - val_loss: 0.1311\n",
      "Epoch 4/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1271\n",
      "Epoch 00004: val_loss improved from 0.13096 to 0.11801, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q1\n",
      "68/68 [==============================] - 159s 2s/step - loss: 0.1271 - val_loss: 0.1180\n",
      "Epoch 5/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1066\n",
      "Epoch 00005: val_loss did not improve from 0.11801\n",
      "68/68 [==============================] - 152s 2s/step - loss: 0.1066 - val_loss: 0.1387\n",
      "Epoch 6/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0916\n",
      "Epoch 00006: val_loss improved from 0.11801 to 0.07075, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q1\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.0916 - val_loss: 0.0708\n",
      "Epoch 7/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0789\n",
      "Epoch 00007: val_loss did not improve from 0.07075\n",
      "68/68 [==============================] - 148s 2s/step - loss: 0.0789 - val_loss: 0.1543\n",
      "Epoch 8/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0575\n",
      "Epoch 00008: val_loss improved from 0.07075 to 0.05084, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q1\n",
      "68/68 [==============================] - 143s 2s/step - loss: 0.0575 - val_loss: 0.0508\n",
      "Epoch 9/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0511\n",
      "Epoch 00009: val_loss did not improve from 0.05084\n",
      "68/68 [==============================] - 133s 2s/step - loss: 0.0511 - val_loss: 0.0871\n",
      "Epoch 10/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 00010: val_loss improved from 0.05084 to 0.03130, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q1\n",
      "68/68 [==============================] - 132s 2s/step - loss: 0.0386 - val_loss: 0.0313\n",
      "Epoch 11/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0275\n",
      "Epoch 00011: val_loss improved from 0.03130 to 0.02872, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q1\n",
      "68/68 [==============================] - 131s 2s/step - loss: 0.0275 - val_loss: 0.0287\n",
      "Epoch 12/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 00012: val_loss did not improve from 0.02872\n",
      "68/68 [==============================] - 131s 2s/step - loss: 0.0385 - val_loss: 0.0835\n",
      "Training on Q2 data:\n",
      "Generating data for Q2!\n",
      "Epoch 1/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 00001: val_loss improved from inf to 0.03949, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q2\n",
      "68/68 [==============================] - 154s 2s/step - loss: 0.0283 - val_loss: 0.0395\n",
      "Epoch 2/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0223\n",
      "Epoch 00002: val_loss improved from 0.03949 to 0.01817, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q2\n",
      "68/68 [==============================] - 153s 2s/step - loss: 0.0223 - val_loss: 0.0182\n",
      "Epoch 3/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 00003: val_loss did not improve from 0.01817\n",
      "68/68 [==============================] - 188s 3s/step - loss: 0.0255 - val_loss: 0.0221\n",
      "Epoch 4/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00004: val_loss did not improve from 0.01817\n",
      "68/68 [==============================] - 205s 3s/step - loss: 0.0181 - val_loss: 0.0550\n",
      "Epoch 5/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 00005: val_loss did not improve from 0.01817\n",
      "68/68 [==============================] - 187s 3s/step - loss: 0.0419 - val_loss: 0.0592\n",
      "Epoch 6/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0243\n",
      "Epoch 00006: val_loss did not improve from 0.01817\n",
      "68/68 [==============================] - 177s 3s/step - loss: 0.0243 - val_loss: 0.0246\n",
      "Epoch 7/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00007: val_loss improved from 0.01817 to 0.01683, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q2\n",
      "68/68 [==============================] - 176s 3s/step - loss: 0.0183 - val_loss: 0.0168\n",
      "Epoch 8/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00008: val_loss did not improve from 0.01683\n",
      "68/68 [==============================] - 177s 3s/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 9/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 00009: val_loss did not improve from 0.01683\n",
      "68/68 [==============================] - 179s 3s/step - loss: 0.0215 - val_loss: 0.0298\n",
      "Epoch 10/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00010: val_loss did not improve from 0.01683\n",
      "68/68 [==============================] - 176s 3s/step - loss: 0.0202 - val_loss: 0.0200\n",
      "Epoch 11/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00011: val_loss did not improve from 0.01683\n",
      "68/68 [==============================] - 176s 3s/step - loss: 0.0192 - val_loss: 0.0174\n",
      "Epoch 12/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00012: val_loss improved from 0.01683 to 0.01494, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q2\n",
      "68/68 [==============================] - 174s 3s/step - loss: 0.0202 - val_loss: 0.0149\n",
      "Training on Q3 data:\n",
      "Generating data for Q3!\n",
      "Epoch 1/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00001: val_loss improved from inf to 0.01263, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q3\n",
      "68/68 [==============================] - 218s 3s/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 2/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00002: val_loss did not improve from 0.01263\n",
      "68/68 [==============================] - 184s 3s/step - loss: 0.0181 - val_loss: 0.0216\n",
      "Epoch 3/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 00003: val_loss did not improve from 0.01263\n",
      "68/68 [==============================] - 186s 3s/step - loss: 0.0200 - val_loss: 0.0218\n",
      "Epoch 4/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 00004: val_loss did not improve from 0.01263\n",
      "68/68 [==============================] - 190s 3s/step - loss: 0.0251 - val_loss: 0.0409\n",
      "Epoch 5/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 00005: val_loss did not improve from 0.01263\n",
      "68/68 [==============================] - 179s 3s/step - loss: 0.0136 - val_loss: 0.0196\n",
      "Epoch 6/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00006: val_loss did not improve from 0.01263\n",
      "68/68 [==============================] - 179s 3s/step - loss: 0.0149 - val_loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 00007: val_loss did not improve from 0.01263\n",
      "68/68 [==============================] - 177s 3s/step - loss: 0.0211 - val_loss: 0.0169\n",
      "Epoch 8/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00008: val_loss did not improve from 0.01263\n",
      "68/68 [==============================] - 171s 3s/step - loss: 0.0145 - val_loss: 0.0224\n",
      "Epoch 9/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 00009: val_loss improved from 0.01263 to 0.01184, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q3\n",
      "68/68 [==============================] - 136s 2s/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 10/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 00010: val_loss did not improve from 0.01184\n",
      "68/68 [==============================] - 133s 2s/step - loss: 0.0112 - val_loss: 0.0142\n",
      "Epoch 11/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 00011: val_loss did not improve from 0.01184\n",
      "68/68 [==============================] - 133s 2s/step - loss: 0.0152 - val_loss: 0.0240\n",
      "Epoch 12/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00012: val_loss did not improve from 0.01184\n",
      "68/68 [==============================] - 132s 2s/step - loss: 0.0162 - val_loss: 0.0156\n",
      "Training on Q4 data:\n",
      "Generating data for Q4!\n",
      "Epoch 1/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00001: val_loss improved from inf to 0.03556, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q4\n",
      "68/68 [==============================] - 157s 2s/step - loss: 0.0166 - val_loss: 0.0356\n",
      "Epoch 2/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00002: val_loss improved from 0.03556 to 0.01245, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q4\n",
      "68/68 [==============================] - 136s 2s/step - loss: 0.0192 - val_loss: 0.0125\n",
      "Epoch 3/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 00003: val_loss did not improve from 0.01245\n",
      "68/68 [==============================] - 132s 2s/step - loss: 0.0135 - val_loss: 0.0250\n",
      "Epoch 4/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 00004: val_loss improved from 0.01245 to 0.01211, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q4\n",
      "68/68 [==============================] - 132s 2s/step - loss: 0.0222 - val_loss: 0.0121\n",
      "Epoch 5/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 00005: val_loss did not improve from 0.01211\n",
      "68/68 [==============================] - 133s 2s/step - loss: 0.0177 - val_loss: 0.0362\n",
      "Epoch 6/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00006: val_loss did not improve from 0.01211\n",
      "68/68 [==============================] - 131s 2s/step - loss: 0.0162 - val_loss: 0.0129\n",
      "Epoch 7/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 00007: val_loss did not improve from 0.01211\n",
      "68/68 [==============================] - 131s 2s/step - loss: 0.0182 - val_loss: 0.0235\n",
      "Epoch 8/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 00008: val_loss improved from 0.01211 to 0.01124, saving model to ../checkpoints/spherenn/spherenn-v3-simple-noisy-mixed-count-kappa-gauss/spherenn-v3-simple-noisy-mixed-count-kappa-gauss-1-Q4\n",
      "68/68 [==============================] - 133s 2s/step - loss: 0.0224 - val_loss: 0.0112\n",
      "Epoch 9/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 00009: val_loss did not improve from 0.01124\n",
      "68/68 [==============================] - 131s 2s/step - loss: 0.0130 - val_loss: 0.0221\n",
      "Epoch 10/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00010: val_loss did not improve from 0.01124\n",
      "68/68 [==============================] - 131s 2s/step - loss: 0.0150 - val_loss: 0.0316\n",
      "Epoch 11/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 00011: val_loss did not improve from 0.01124\n",
      "68/68 [==============================] - 131s 2s/step - loss: 0.0133 - val_loss: 0.0202\n",
      "Epoch 12/12\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00012: val_loss did not improve from 0.01124\n",
      "68/68 [==============================] - 130s 2s/step - loss: 0.0186 - val_loss: 0.0315\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fa66a3b54d8bc017\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fa66a3b54d8bc017\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Q1 data\n",
      "Generating data for Q1!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:368: UserWarning: If you are not specifying the input dtype and using the default np.float64 dtype of read_map(), please consider that it will change in a future version to None as to keep the same dtype of the input file: please explicitly set the dtype if it is important to you.\n",
      "  warnings.warn(\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:391: UserWarning: NSIDE = 1024\n",
      "  warnings.warn(\"NSIDE = {0:d}\".format(nside))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:400: UserWarning: ORDERING = NESTED in fits file\n",
      "  warnings.warn(\"ORDERING = {0:s} in fits file\".format(ordering))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:428: UserWarning: INDXSCHM = IMPLICIT\n",
      "  warnings.warn(\"INDXSCHM = {0:s}\".format(schm))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/numba/core/ir_utils.py:2031: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'g' of function 'accelerated_noiseless_shear'.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"../../.local/lib/python3.8/site-packages/deep_dss-0.1.0-py3.8.egg/deep_dss/helpers.py\", line 348:\n",
      "@jit(nopython=True)\n",
      "def accelerated_noiseless_shear(g, npix=NPIX, multiplier=1.0):\n",
      "^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:368: UserWarning: If you are not specifying the input dtype and using the default np.float64 dtype of read_map(), please consider that it will change in a future version to None as to keep the same dtype of the input file: please explicitly set the dtype if it is important to you.\n",
      "  warnings.warn(\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:391: UserWarning: NSIDE = 1024\n",
      "  warnings.warn(\"NSIDE = {0:d}\".format(nside))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:400: UserWarning: ORDERING = NESTED in fits file\n",
      "  warnings.warn(\"ORDERING = {0:s} in fits file\".format(ordering))\n",
      "/Users/adiraju/opt/anaconda3/envs/deep_dss/lib/python3.8/site-packages/healpy/fitsfunc.py:428: UserWarning: INDXSCHM = IMPLICIT\n",
      "  warnings.warn(\"INDXSCHM = {0:s}\".format(schm))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Q2 data\n",
      "Generating data for Q2!\n",
      "Processing Q3 data\n",
      "Generating data for Q3!\n"
     ]
    }
   ],
   "source": [
    "results = full_predictions_and_truths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preds_vs_truths(results, \"SphereNN Estimates from Noiseless Shear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(results, \"SphereNN Residuals from Noiseless Shear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_losses(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_predictions(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
